## 播放音乐

1.创建一个上下文，处理封装格式

2.打开上下文

3.打开流

4.将音乐的流的下标找出来

```
formatContext = avformat_alloc_context();  //处理封装格式的
AVDictionary *opts = NULL;//从字典中取值
av_dict_set(&opts, "timeout", "30000000", 0); //如果这么久都没有打开，就认为有问题
int ret = avformat_open_input(&formatContext,m_url,NULL,&opts);//打开文件
if (ret){   //为0表示成功
    LOGCATE("open file failed");
    return;
}else{
    LOGCATE("open file success");
}

avformat_find_stream_info(formatContext,NULL); //读取数据流信息   读取视频流  解析出来

//便利
for(int i= 0; i<formatContext->nb_streams;i++){
    //视频流
    if(formatContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO){
        video_stream_index = i;
    } else if(formatContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO){
        audeo_stream_index = i;
    }
}
```

5.创建引擎

```c++
void AudioDecor::createEngine(){
    slCreateEngine(&engineObject,0,NULL,0,NULL,NULL);//创建引擎
    (*engineObject)->Realize(engineObject,SL_BOOLEAN_FALSE);//实现engineObject接口对象
    (*engineObject)->GetInterface(engineObject,SL_IID_ENGINE,&engineEngine);//通过引擎调用接口初始化SLEngineItf
}
```

说明

```
SL_API SLresult SLAPIENTRY slCreateEngine(
   SLObjectItf             *pEngine,
   SLuint32                numOptions,
   const SLEngineOption    *pEngineOptions,
   SLuint32                numInterfaces,
   const SLInterfaceID     *pInterfaceIds,
   const SLboolean         * pInterfaceRequired
);
```

6.创建混音

```java
//创建混音器
void AudioDecor::createMixVolume(){
    (*engineEngine)->CreateOutputMix(engineEngine,&outputMixObject,0,0,0);//用引擎对象创建混音器接口对象
    (*outputMixObject)->Realize(outputMixObject,SL_BOOLEAN_FALSE);//实现混音器接口对象
    SLresult   sLresult = (*outputMixObject)->GetInterface(outputMixObject,SL_IID_ENVIRONMENTALREVERB,&outputMixEnvironmentalReverb);//利用混音器实例对象接口初始化具体的混音器对象
    //设置
    if (SL_RESULT_SUCCESS == sLresult) {
        (*outputMixEnvironmentalReverb)->
                SetEnvironmentalReverbProperties(outputMixEnvironmentalReverb, &settings);
    }
}
```

7.创建播放器

```java
int AudioDecor::createFFmpeg(int *rate,int *channel){
    AVCodecParameters *avCodecParameters = formatContext->streams[audeo_stream_index]->codecpar;
//    获取音频编解码器   废弃
//    pCodecCtx=avcodec_find_decoder(avCodecParameters->codec_id);
    LOGE("获取视频编码器上下文 %p  ",pCodecCtx);
    pCodex = avcodec_find_decoder(avCodecParameters->codec_id);
    pCodecCtx = avcodec_alloc_context3(pCodex);
    avcodec_parameters_to_context(pCodecCtx,avCodecParameters);
    LOGE("获取视频编码 %p",pCodex);
    if (avcodec_open2(pCodecCtx, pCodex, NULL)<0) {
    }
    packet = (AVPacket *)av_malloc(sizeof(AVPacket));
//    音频数据
    frame = av_frame_alloc();
//    mp3  里面所包含的编码格式   转换成  pcm   SwcContext
    swrContext = swr_alloc();
//    44100*2
    out_buffer = (uint8_t *) av_malloc(44100 * 2);
    uint64_t  out_ch_layout=AV_CH_LAYOUT_STEREO;
//    输出采样位数  16位
    enum AVSampleFormat out_formart=AV_SAMPLE_FMT_S16;
//输出的采样率必须与输入相同
    int out_sample_rate = pCodecCtx->sample_rate;
    swr_alloc_set_opts(
            swrContext,
            out_ch_layout,
            out_formart,
            out_sample_rate,
            pCodecCtx->channel_layout,
            pCodecCtx->sample_fmt,
            pCodecCtx->sample_rate,
            0,
            NULL);
    swr_init(swrContext);
//    获取通道数  2
    out_channer_nb =
            av_get_channel_layout_nb_channels(
                    AV_CH_LAYOUT_STEREO);
    *rate = pCodecCtx->sample_rate;
    *channel = pCodecCtx->channels;
    return 0;
}
```

8.创建一个SDL

```
SLDataLocator_AndroidBufferQueue android_queue =
        {SL_DATALOCATOR_ANDROIDSIMPLEBUFFERQUEUE,2};
/**
typedef struct SLDataFormat_PCM_ {
    SLuint32      formatType;  pcm
    SLuint32      numChannels;  通道数
    SLuint32      samplesPerSec;  采样率
    SLuint32      bitsPerSample;  采样位数
    SLuint32      containerSize;  包含位数
    SLuint32      channelMask;     立体声
    SLuint32      endianness;    end标志位
} SLDataFormat_PCM;
 */
SLDataFormat_PCM pcm = {SL_DATAFORMAT_PCM,static_cast<SLuint32>(channels),
                        static_cast<SLuint32>(rate*1000)
        ,SL_PCMSAMPLEFORMAT_FIXED_16
        ,SL_PCMSAMPLEFORMAT_FIXED_16
        ,SL_SPEAKER_FRONT_LEFT|SL_SPEAKER_FRONT_RIGHT,SL_BYTEORDER_LITTLEENDIAN};
SLDataSource dataSource = {&android_queue,&pcm};
SLDataLocator_OutputMix slDataLocator_outputMix={SL_DATALOCATOR_OUTPUTMIX,outputMixObject};
SLDataSink slDataSink = {&slDataLocator_outputMix,NULL};
const SLInterfaceID ids[3]={SL_IID_BUFFERQUEUE,SL_IID_EFFECTSEND,SL_IID_VOLUME};
const SLboolean req[3]={SL_BOOLEAN_FALSE,SL_BOOLEAN_FALSE,SL_BOOLEAN_FALSE};
LOGE("执行到此处");
(*engineEngine)->CreateAudioPlayer(engineEngine,&audioplayer,&dataSource,&slDataSink,3,ids,req);
(*audioplayer)->Realize(audioplayer,SL_BOOLEAN_FALSE);
LOGE("执行到此处2");
(*audioplayer)->GetInterface(audioplayer,SL_IID_PLAY,&slPlayItf);//初始化播放器
//注册缓冲区,通过缓冲区里面 的数据进行播放
(*audioplayer)->GetInterface(audioplayer,SL_IID_BUFFERQUEUE,&slBufferQueueItf);
//设置回调接口
(*slBufferQueueItf)->RegisterCallback(slBufferQueueItf,getQueueCallBack,NULL);
//播放
(*slPlayItf)->SetPlayState(slPlayItf,SL_PLAYSTATE_PLAYING);
//开始播放
getQueueCallBack(slBufferQueueItf,NULL);
```

9.回调函数，将pcm数据写入

```java
//将pcm数据添加到缓冲区中
void AudioDecor::getQueueCallBack(SLAndroidSimpleBufferQueueItf  slBufferQueueItf, void* context){
//    if (audioDemo==NULL){
    audioDecor->xx();
//    }
}

void AudioDecor::xx() {
    buffersize=0;
    getPcm(&buffer,&buffersize);
    if(buffer!=NULL&&buffersize!=0){
        //将得到的数据加入到队列中
        (*slBufferQueueItf)->Enqueue(slBufferQueueItf,buffer,buffersize);
    }
}
```

## 处理过程

- 注册 
- 打开文件
- 找出视频和音频流
- 得到解码器
- 通过Avpacket得到数据



## 阅读一次雷神的代码

```java

#include <stdio.h>
 
#define __STDC_CONSTANT_MACROS
 
#ifdef _WIN32
//Windows
extern "C"
{
#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
#include "libswscale/swscale.h"
#include "SDL/SDL.h"
};
#else
//Linux...
#ifdef __cplusplus
extern "C"
{
#endif
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>
#include <SDL/SDL.h>
#ifdef __cplusplus
};
#endif
#endif
 
 
//Full Screen
#define SHOW_FULLSCREEN 0
//Output YUV420P 
#define OUTPUT_YUV420P 0
 
 
int main(int argc, char* argv[])
{
	//FFmpeg
	AVFormatContext	*pFormatCtx;
	int				i, videoindex;
	AVCodecContext	*pCodecCtx;
	AVCodec			*pCodec;
	AVFrame	*pFrame,*pFrameYUV;
	AVPacket *packet;
	struct SwsContext *img_convert_ctx;
	//SDL
	int screen_w,screen_h;
	SDL_Surface *screen; 
	SDL_VideoInfo *vi;
	SDL_Overlay *bmp; 
	SDL_Rect rect;
 
	FILE *fp_yuv;
	int ret, got_picture;
	char filepath[]="bigbuckbunny_480x272.h265";
 	
    //注册
	av_register_all();
	//注册网络
    avformat_network_init();
    //创建封装上下文
	pFormatCtx = avformat_alloc_context();
 	//将文件中的参数设置到上下文中
	if(avformat_open_input(&pFormatCtx,filepath,NULL,NULL)!=0){
		printf("Couldn't open input stream.\n");
		return -1;
	}
    //获取流
	if(avformat_find_stream_info(pFormatCtx,NULL)<0){
		printf("Couldn't find stream information.\n");
		return -1;
	}
	videoindex=-1;
    //找视频流
	for(i=0; i<pFormatCtx->nb_streams; i++) 
		if(pFormatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO){
			videoindex=i;
			break;
		}
	if(videoindex==-1){
		printf("Didn't find a video stream.\n");
		return -1;
	}
    //得到解码器的上下文
	pCodecCtx=pFormatCtx->streams[videoindex]->codec;
	//得到解码器
    pCodec=avcodec_find_decoder(pCodecCtx->codec_id);
	if(pCodec==NULL){
		printf("Codec not found.\n");
		return -1;
	}
    //从封装上下文中读取资源（使用解码器获取资源）
	if(avcodec_open2(pCodecCtx, pCodec,NULL)<0){
		printf("Could not open codec.\n");
		return -1;
	}
	
	pFrame=av_frame_alloc();
	pFrameYUV=av_frame_alloc();
	//uint8_t *out_buffer=(uint8_t *)av_malloc(avpicture_get_size(PIX_FMT_YUV420P, pCodecCtx->width, pCodecCtx->height));
	//avpicture_fill((AVPicture *)pFrameYUV, out_buffer, PIX_FMT_YUV420P, pCodecCtx->width, pCodecCtx->height);
	//SDL---------------------------- 初始化SDL
	if(SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER)) {  
		printf( "Could not initialize SDL - %s\n", SDL_GetError()); 
		return -1;
	} 
 
	
 
    //适配器全屏  和  适配内容
#if SHOW_FULLSCREEN
	vi = SDL_GetVideoInfo();
	screen_w = vi->current_w;
	screen_h = vi->current_h;
	screen = SDL_SetVideoMode(screen_w, screen_h, 0,SDL_FULLSCREEN);
#else
	screen_w = pCodecCtx->width;
	screen_h = pCodecCtx->height;
	screen = SDL_SetVideoMode(screen_w, screen_h, 0,0);
#endif
 
	if(!screen) {  
		printf("SDL: could not set video mode - exiting:%s\n",SDL_GetError());  
		return -1;
	}
 
	bmp = SDL_CreateYUVOverlay(pCodecCtx->width, pCodecCtx->height,SDL_YV12_OVERLAY, screen); 
 
	rect.x = 0;    
	rect.y = 0;    
	rect.w = screen_w;    
	rect.h = screen_h;  
	//SDL End------------------------
    //创建AVPacket
	packet=(AVPacket *)av_malloc(sizeof(AVPacket));
	//Output Information-----------------------------
	printf("------------- File Information ------------------\n");
    //打印详细信息
	av_dump_format(pFormatCtx,0,filepath,0);
	printf("-------------------------------------------------\n");
 
#if OUTPUT_YUV420P 
    //二进制写入
    fp_yuv=fopen("output.yuv","wb+");  
#endif  
 
	SDL_WM_SetCaption("Simplest FFmpeg Player",NULL);
 	//初始化一个sws
    /**
    参数1：被转换源的宽

参数2：被转换源的高

参数3：被转换源的格式，eg：YUV、RGB……（枚举格式，也可以直接用枚举的代号表示eg：AV_PIX_FMT_YUV420P这些枚举的格式在libavutil/pixfmt.h中列出）

参数4：转换后指定的宽

参数5：转换后指定的高

参数6：转换后指定的格式同参数3的格式

参数7：转换所使用的算法，

参数8：NULL

参数9：NULL

参数10：NULL
    */
	img_convert_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height, pCodecCtx->pix_fmt, pCodecCtx->width, pCodecCtx->height, PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL); 
	//------------------------------
    //一帧一帧的读取
	while(av_read_frame(pFormatCtx, packet)>=0){
		if(packet->stream_index==videoindex){
			//解码
			ret = avcodec_decode_video2(pCodecCtx, pFrame, &got_picture, packet);
			if(ret < 0){
				printf("Decode Error.\n");
				return -1;
			}
			if(got_picture){
				SDL_LockYUVOverlay(bmp);
				pFrameYUV->data[0]=bmp->pixels[0];
				pFrameYUV->data[1]=bmp->pixels[2];
				pFrameYUV->data[2]=bmp->pixels[1];     
				pFrameYUV->linesize[0]=bmp->pitches[0];
				pFrameYUV->linesize[1]=bmp->pitches[2];   
				pFrameYUV->linesize[2]=bmp->pitches[1];
                //数据处理
				sws_scale(img_convert_ctx, (const uint8_t* const*)pFrame->data, pFrame->linesize, 0, 
					pCodecCtx->height, pFrameYUV->data, pFrameYUV->linesize);
#if OUTPUT_YUV420P
				int y_size=pCodecCtx->width*pCodecCtx->height;  
				fwrite(pFrameYUV->data[0],1,y_size,fp_yuv);    //Y 
				fwrite(pFrameYUV->data[1],1,y_size/4,fp_yuv);  //U
				fwrite(pFrameYUV->data[2],1,y_size/4,fp_yuv);  //V
#endif
				
				SDL_UnlockYUVOverlay(bmp); 
 
				SDL_DisplayYUVOverlay(bmp, &rect); 
				//Delay 40ms
				SDL_Delay(40);
			}
		}
		av_free_packet(packet);
	}
 
	//FIX: Flush Frames remained in Codec
	while (1) {
		ret = avcodec_decode_video2(pCodecCtx, pFrame, &got_picture, packet);
		if (ret < 0)
			break;
		if (!got_picture)
			break;
		sws_scale(img_convert_ctx, (const uint8_t* const*)pFrame->data, pFrame->linesize, 0, pCodecCtx->height, pFrameYUV->data, pFrameYUV->linesize);
		
		SDL_LockYUVOverlay(bmp);
		pFrameYUV->data[0]=bmp->pixels[0];
		pFrameYUV->data[1]=bmp->pixels[2];
		pFrameYUV->data[2]=bmp->pixels[1];     
		pFrameYUV->linesize[0]=bmp->pitches[0];
		pFrameYUV->linesize[1]=bmp->pitches[2];   
		pFrameYUV->linesize[2]=bmp->pitches[1];
#if OUTPUT_YUV420P
		int y_size=pCodecCtx->width*pCodecCtx->height;  
		fwrite(pFrameYUV->data[0],1,y_size,fp_yuv);    //Y 
		fwrite(pFrameYUV->data[1],1,y_size/4,fp_yuv);  //U
		fwrite(pFrameYUV->data[2],1,y_size/4,fp_yuv);  //V
#endif
 
		SDL_UnlockYUVOverlay(bmp); 
		SDL_DisplayYUVOverlay(bmp, &rect); 
		//Delay 40ms
		SDL_Delay(40);
	}
 
	sws_freeContext(img_convert_ctx);
 
#if OUTPUT_YUV420P 
    fclose(fp_yuv);
#endif 
 
	SDL_Quit();
 
	//av_free(out_buffer);
	av_free(pFrameYUV);
	avcodec_close(pCodecCtx);
	avformat_close_input(&pFormatCtx);
 
	return 0;
}
————————————————
版权声明：本文为CSDN博主「雷霄骅」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/leixiaohua1020/article/details/8652605
```

